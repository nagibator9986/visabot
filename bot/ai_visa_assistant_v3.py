"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘   ğŸ¤– AI VISA ASSISTANT v3.1 â€” BCD TRAVEL Kazakhstan                         â•‘
â•‘   Ğ˜Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ñ‹Ğ¹ AI-Ğ°Ğ³ĞµĞ½Ñ‚ Ğ´Ğ»Ñ Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²Ğ¸Ğ·Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°ÑĞ²Ğ¾Ğº                    â•‘
â•‘   Â© 2024-2025 BCD TRAVEL Kazakhstan. All Rights Reserved.                   â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
"""

from __future__ import annotations
from dataclasses import dataclass, field
from typing import List, Optional, Dict, Any, Union, Tuple, Set
from enum import Enum
import os, logging, json, re
from datetime import datetime

try:
    from openai_client import generate_chat_completion
except ImportError:
    def generate_chat_completion(messages, model="gpt-4o", max_tokens=500, temperature=0.2):
        raise NotImplementedError("OpenAI client not found")

logger = logging.getLogger(__name__)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ¨ AI Ğ‘Ğ Ğ•ĞĞ”Ğ˜ĞĞ“
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass(frozen=True)
class AIBranding:
    agent_name: str = "AI Visa Assistant"
    agent_version: str = "3.1"
    company_name: str = "BCD TRAVEL Kazakhstan"
    robot_emoji: str = "ğŸ¤–"
    sparkle_emoji: str = "âœ¨"
    check_emoji: str = "âœ…"
    arrow_emoji: str = "â¤"
    star_emoji: str = "â­"
    info_emoji: str = "â„¹ï¸"
    warning_emoji: str = "âš ï¸"
    link_emoji: str = "ğŸ”—"
    form_emoji: str = "ğŸ“‹"
    urgent_emoji: str = "ğŸš¨"
    line_thin: str = "â”€" * 50
    
    def get_footer_ru(self) -> str:
        return f"\n{self.line_thin}\n{self.robot_emoji} Ğ­Ñ‚Ğ¾ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾ {self.agent_name} v{self.agent_version}\n{self.sparkle_emoji} Ğ˜Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²Ğ¸Ğ·Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°ÑĞ²Ğ¾Ğº\n\nĞ¡ ÑƒĞ²Ğ°Ğ¶ĞµĞ½Ğ¸ĞµĞ¼,\n{self.company_name}\n{self.star_emoji} visa@bcdtravel.kz\n"
    
    def get_footer_en(self) -> str:
        return f"\n{self.line_thin}\n{self.robot_emoji} This message was generated by {self.agent_name} v{self.agent_version}\n{self.sparkle_emoji} Intelligent Visa Processing System\n\nBest regards,\n{self.company_name}\n{self.star_emoji} visa@bcdtravel.kz\n"

AI_BRAND = AIBranding()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âš™ï¸ ĞšĞĞĞ¤Ğ˜Ğ“Ğ£Ğ ĞĞ¦Ğ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass(frozen=True)
class Config:
    mailbox_upn: str = field(default_factory=lambda: os.getenv("MAILBOX_UPN", "RobotVisa@itplus.kz"))
    non_standard_forward_email: str = field(default_factory=lambda: os.getenv("NON_STANDARD_FORWARD_EMAIL", "specialists@bcdtravel.kz"))
    default_model: str = field(default_factory=lambda: os.getenv("OPENAI_MODEL", "gpt-4o"))
    max_tokens_reply: int = 1000
    temperature: float = 0.25
    
    # URL ĞĞ½ĞºĞµÑ‚
    questionnaire_poland_url: Optional[str] = field(default_factory=lambda: os.getenv("QUESTIONNAIRE_POLAND_URL") or os.getenv("FORM_POLAND_URL"))
    questionnaire_schengen_url: Optional[str] = field(default_factory=lambda: os.getenv("QUESTIONNAIRE_SCHENGEN_URL") or os.getenv("FORM_SCHENGEN_URL"))
    questionnaire_usa_url: Optional[str] = field(default_factory=lambda: os.getenv("QUESTIONNAIRE_USA_URL") or os.getenv("FORM_USA_URL"))
    questionnaire_generic_url: Optional[str] = field(default_factory=lambda: os.getenv("QUESTIONNAIRE_GENERIC_URL") or os.getenv("FORM_GENERIC_URL"))
    
    # ID Ğ¿Ğ¾Ğ»ĞµĞ¹ Ğ² Google Forms Ğ´Ğ»Ñ pre-filled link (entry.XXXXXX)
    entry_id_poland: str = field(default_factory=lambda: os.getenv("GF_ENTRY_ID_POLAND", ""))
    entry_id_schengen: str = field(default_factory=lambda: os.getenv("GF_ENTRY_ID_SCHENGEN", ""))
    entry_id_usa: str = field(default_factory=lambda: os.getenv("GF_ENTRY_ID_USA", ""))
    entry_id_generic: str = field(default_factory=lambda: os.getenv("GF_ENTRY_ID_GENERIC", ""))

CONFIG = Config()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“Š ĞŸĞ•Ğ Ğ•Ğ§Ğ˜Ğ¡Ğ›Ğ•ĞĞ˜Ğ¯
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Language(Enum):
    RUSSIAN = "ru"
    ENGLISH = "en"
    KAZAKH = "kk"
    @classmethod
    def default(cls): return cls.RUSSIAN

class Intent(Enum):
    WANT_APPLY = "want_apply"
    SEND_DOCS = "send_docs"
    INFO_REQUEST = "info_request"
    FOLLOWUP = "followup"
    COMPLAINT = "complaint"
    GRATITUDE = "gratitude"
    CANCELLATION = "cancellation"
    RESCHEDULE = "reschedule"
    PAYMENT = "payment"
    OTHER = "other"
    @classmethod
    def default(cls): return cls.OTHER

class LeadStatus(Enum):
    NEW = "new"
    INFO_PROVIDED = "info_provided"
    QUESTIONNAIRE_SENT = "questionnaire_sent"
    QUESTIONNAIRE_FILLED = "questionnaire_filled"
    DOCS_IN_PROGRESS = "docs_in_progress"
    DOCS_COLLECTED = "docs_collected"
    SUBMITTED = "submitted"
    APPROVED = "approved"
    REJECTED = "rejected"
    COMPLETED = "completed"
    CANCELLED = "cancelled"
    @classmethod
    def default(cls): return cls.NEW
    @classmethod
    def from_string(cls, s):
        if not s: return cls.default()
        try: return cls(s.lower().strip())
        except: return cls.default()

class UrgencyLevel(Enum):
    CRITICAL = 5
    VERY_HIGH = 4
    HIGH = 3
    MEDIUM = 2
    NORMAL = 1
    LOW = 0
    @property
    def emoji(self):
        return {5: "ğŸ”´", 4: "ğŸŸ ", 3: "ğŸŸ¡", 2: "ğŸŸ¢", 1: "ğŸ”µ", 0: "âšª"}.get(self.value, "âšª")

class VisaCategory(Enum):
    STANDARD = "standard"
    NON_STANDARD = "non_standard"

class Sentiment(Enum):
    VERY_POSITIVE = "very_positive"
    POSITIVE = "positive"
    NEUTRAL = "neutral"
    NEGATIVE = "negative"
    VERY_NEGATIVE = "very_negative"
    @property
    def emoji(self):
        return {"very_positive": "ğŸ˜„", "positive": "ğŸ™‚", "neutral": "ğŸ˜", "negative": "ğŸ˜Ÿ", "very_negative": "ğŸ˜ "}.get(self.value, "ğŸ˜")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¦ ĞœĞĞ”Ğ•Ğ›Ğ˜ Ğ”ĞĞĞĞ«Ğ¥
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class Message:
    from_address: str
    subject: str
    body: str
    received_at: Optional[str] = None
    attachments: List[str] = field(default_factory=list)
    
    @property
    def full_text(self):
        parts = []
        if self.subject: parts.append(f"[Ğ¢ĞµĞ¼Ğ°: {self.subject}]")
        if self.body: parts.append(self.body)
        return "\n".join(parts)
    
    @classmethod
    def from_dict(cls, data):
        from_data = data.get("from", {})
        email_data = from_data.get("emailAddress", {}) if isinstance(from_data, dict) else {}
        body_data = data.get("body", {})
        body_content = body_data.get("content", "") if isinstance(body_data, dict) else str(body_data)
        return cls(
            from_address=email_data.get("address", "") if isinstance(email_data, dict) else "",
            subject=data.get("subject", ""),
            body=data.get("bodyPreview", "") or body_content,
            received_at=data.get("receivedDateTime"),
            attachments=[a.get("name", "") for a in data.get("attachments", []) if isinstance(a, dict)],
        )
    
    def get_clean_body(self):
        text = re.sub(r'<[^>]+>', ' ', self.body)
        text = re.sub(r'\s+', ' ', text)
        return text.strip()

@dataclass
class Country:
    code: str
    names: Set[str]
    category: VisaCategory
    questionnaire_type: Optional[str] = None
    processing_notes: Optional[str] = None

@dataclass
class QuestionnaireLinks:
    poland: Optional[str] = None
    schengen: Optional[str] = None
    usa: Optional[str] = None
    generic: Optional[str] = None
    
    @classmethod
    def from_config(cls):
        return cls(poland=CONFIG.questionnaire_poland_url, schengen=CONFIG.questionnaire_schengen_url,
                   usa=CONFIG.questionnaire_usa_url, generic=CONFIG.questionnaire_generic_url)
    
    def get_personal_link(self, type_code: str, lead_id: Union[int, str, None]) -> Optional[str]:
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¿ĞµÑ€ÑĞ¾Ğ½Ğ°Ğ»ÑŒĞ½ÑƒÑ ÑÑÑ‹Ğ»ĞºÑƒ Ñ Ğ¿Ñ€ĞµĞ´Ğ·Ğ°Ğ¿Ğ¾Ğ»Ğ½ĞµĞ½Ğ½Ñ‹Ğ¼ Lead ID.
        """
        base_url = getattr(self, type_code, None)
        if not base_url: return None
        if not lead_id: return base_url

        entry_id = getattr(CONFIG, f"entry_id_{type_code}", "")
        
        if entry_id and "docs.google.com" in base_url:
            separator = "&" if "?" in base_url else "?"
            return f"{base_url}{separator}{entry_id}={lead_id}"
        
        return base_url

@dataclass
class ThreadAnalysis:
    language: Language
    detected_country: Optional[Country]
    intent: Intent
    urgency: UrgencyLevel
    sentiment: Sentiment
    previous_status: LeadStatus
    new_status: LeadStatus
    offer_poland_questionnaire: bool = False
    offer_schengen_questionnaire: bool = False
    offer_usa_questionnaire: bool = False
    offer_generic_questionnaire: bool = False
    is_non_standard_destination: bool = False
    has_attachments: bool = False
    attachment_count: int = 0
    forward_to_email: Optional[str] = None
    forward_reason: Optional[str] = None
    confidence_score: float = 0.0
    analysis_notes: List[str] = field(default_factory=list)
    
    @property
    def country_code(self): return self.detected_country.code if self.detected_country else None
    @property
    def needs_questionnaire(self): return any([self.offer_poland_questionnaire, self.offer_schengen_questionnaire, self.offer_usa_questionnaire, self.offer_generic_questionnaire])
    @property
    def questionnaire_type(self):
        if self.offer_poland_questionnaire: return "poland"
        if self.offer_schengen_questionnaire: return "schengen"
        if self.offer_usa_questionnaire: return "usa"
        if self.offer_generic_questionnaire: return "generic"
        return None
    @property
    def is_urgent(self): return self.urgency in (UrgencyLevel.CRITICAL, UrgencyLevel.VERY_HIGH, UrgencyLevel.HIGH)
    
    def to_dict(self):
        return {
            "language": self.language.value, "country": self.country_code, "intent": self.intent.value,
            "urgency_level": self.urgency.name, "urgency_emoji": self.urgency.emoji,
            "sentiment": self.sentiment.value, "sentiment_emoji": self.sentiment.emoji,
            "previous_status": self.previous_status.value, "new_status": self.new_status.value,
            "offer_poland_questionnaire": self.offer_poland_questionnaire,
            "offer_schengen_questionnaire": self.offer_schengen_questionnaire,
            "offer_usa_questionnaire": self.offer_usa_questionnaire,
            "offer_generic_questionnaire": self.offer_generic_questionnaire,
            "is_urgent": self.is_urgent, "is_non_standard_destination": self.is_non_standard_destination,
            "forward_to_email": self.forward_to_email, "questionnaire_type": self.questionnaire_type,
            "needs_questionnaire": self.needs_questionnaire, "confidence_score": self.confidence_score,
            "has_attachments": self.has_attachments,
            # ĞĞ±Ñ€Ğ°Ñ‚Ğ½Ğ°Ñ ÑĞ¾Ğ²Ğ¼ĞµÑÑ‚Ğ¸Ğ¼Ğ¾ÑÑ‚ÑŒ
            "offer_poland_form": self.offer_poland_questionnaire, "offer_schengen_form": self.offer_schengen_questionnaire,
            "offer_usa_form": self.offer_usa_questionnaire, "offer_generic_form": self.offer_generic_questionnaire,
            "needs_form": self.needs_questionnaire, "form_code": self.questionnaire_type,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸŒ Ğ‘ĞĞ—Ğ Ğ¡Ğ¢Ğ ĞĞ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CountryDatabase:
    SCHENGEN_CODES = frozenset({"AT", "BE", "CZ", "DK", "EE", "FI", "FR", "DE", "GR", "HU", "IS", "IT", "LV", "LI", "LT", "LU", "MT", "NL", "NO", "PL", "PT", "SK", "SI", "ES", "SE", "CH"})
    NON_STANDARD_CODES = frozenset({"GB", "CA", "AU", "NZ", "JP", "CN", "KR", "IN", "BR", "MX", "TR", "AE", "SA", "ZA", "EG", "TH", "VN", "SG", "IL", "MY", "ID"})
    
    def __init__(self):
        self._countries: Dict[str, Country] = {}
        self._keyword_index: Dict[str, str] = {}
        self._build_database()
    
    def _add(self, c): 
        self._countries[c.code] = c
        for n in c.names: self._keyword_index[n.lower()] = c.code
    
    def _build_database(self):
        self._add(Country("PL", {"poland", "Ğ¿Ğ¾Ğ»ÑŒÑˆĞ°", "Ğ¿Ğ¾Ğ»ÑŒÑˆÑƒ", "warsaw", "Ğ²Ğ°Ñ€ÑˆĞ°Ğ²Ğ°", "krakow", "ĞºÑ€Ğ°ĞºĞ¾Ğ²", "gdansk", "Ğ³Ğ´Ğ°Ğ½ÑŒÑĞº"}, VisaCategory.STANDARD, "poland"))
        self._add(Country("US", {"usa", "u.s.", "united states", "america", "Ğ°Ğ¼ĞµÑ€Ğ¸ĞºĞ°", "ÑÑˆĞ°", "ÑˆÑ‚Ğ°Ñ‚Ñ‹", "new york", "Ğ½ÑŒÑ-Ğ¹Ğ¾Ñ€Ğº", "los angeles", "Ğ»Ğ¾Ñ-Ğ°Ğ½Ğ´Ğ¶ĞµĞ»ĞµÑ", "washington", "Ğ²Ğ°ÑˆĞ¸Ğ½Ğ³Ñ‚Ğ¾Ğ½", "miami", "Ğ¼Ğ°Ğ¹Ğ°Ğ¼Ğ¸", "chicago", "Ñ‡Ğ¸ĞºĞ°Ğ³Ğ¾", "las vegas", "Ğ»Ğ°Ñ-Ğ²ĞµĞ³Ğ°Ñ"}, VisaCategory.STANDARD, "usa", "Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ ÑĞ¾Ğ±ĞµÑĞµĞ´Ğ¾Ğ²Ğ°Ğ½Ğ¸Ğµ"))
        self._add(Country("FR", {"france", "Ñ„Ñ€Ğ°Ğ½Ñ†Ğ¸Ñ", "Ñ„Ñ€Ğ°Ğ½Ñ†Ğ¸Ñ", "paris", "Ğ¿Ğ°Ñ€Ğ¸Ğ¶", "nice", "Ğ½Ğ¸Ñ†Ñ†Ğ°", "lyon", "Ğ»Ğ¸Ğ¾Ğ½", "cannes", "ĞºĞ°Ğ½Ğ½Ñ‹"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("DE", {"germany", "Ğ³ĞµÑ€Ğ¼Ğ°Ğ½Ğ¸Ñ", "Ğ³ĞµÑ€Ğ¼Ğ°Ğ½Ğ¸Ñ", "berlin", "Ğ±ĞµÑ€Ğ»Ğ¸Ğ½", "munich", "Ğ¼ÑĞ½Ñ…ĞµĞ½", "frankfurt", "Ñ„Ñ€Ğ°Ğ½ĞºÑ„ÑƒÑ€Ñ‚", "hamburg", "Ğ³Ğ°Ğ¼Ğ±ÑƒÑ€Ğ³"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("IT", {"italy", "Ğ¸Ñ‚Ğ°Ğ»Ğ¸Ñ", "Ğ¸Ñ‚Ğ°Ğ»Ğ¸Ñ", "rome", "Ñ€Ğ¸Ğ¼", "milan", "Ğ¼Ğ¸Ğ»Ğ°Ğ½", "venice", "Ğ²ĞµĞ½ĞµÑ†Ğ¸Ñ", "florence", "Ñ„Ğ»Ğ¾Ñ€ĞµĞ½Ñ†Ğ¸Ñ"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("ES", {"spain", "Ğ¸ÑĞ¿Ğ°Ğ½Ğ¸Ñ", "Ğ¸ÑĞ¿Ğ°Ğ½Ğ¸Ñ", "barcelona", "Ğ±Ğ°Ñ€ÑĞµĞ»Ğ¾Ğ½Ğ°", "madrid", "Ğ¼Ğ°Ğ´Ñ€Ğ¸Ğ´", "valencia", "Ğ²Ğ°Ğ»ĞµĞ½ÑĞ¸Ñ", "ibiza", "Ğ¸Ğ±Ğ¸Ñ†Ğ°"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("NL", {"netherlands", "Ğ½Ğ¸Ğ´ĞµÑ€Ğ»Ğ°Ğ½Ğ´Ñ‹", "Ğ³Ğ¾Ğ»Ğ»Ğ°Ğ½Ğ´Ğ¸Ñ", "holland", "amsterdam", "Ğ°Ğ¼ÑÑ‚ĞµÑ€Ğ´Ğ°Ğ¼"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("AT", {"austria", "Ğ°Ğ²ÑÑ‚Ñ€Ğ¸Ñ", "Ğ²ĞµĞ½Ğ°", "vienna", "wien", "salzburg", "Ğ·Ğ°Ğ»ÑŒÑ†Ğ±ÑƒÑ€Ğ³"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("CZ", {"czech", "czechia", "Ñ‡ĞµÑ…Ğ¸Ñ", "prague", "Ğ¿Ñ€Ğ°Ğ³Ğ°"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("GR", {"greece", "Ğ³Ñ€ĞµÑ†Ğ¸Ñ", "Ğ³Ñ€ĞµÑ†Ğ¸Ñ", "athens", "Ğ°Ñ„Ğ¸Ğ½Ñ‹", "santorini", "ÑĞ°Ğ½Ñ‚Ğ¾Ñ€Ğ¸Ğ½Ğ¸", "crete", "ĞºÑ€Ğ¸Ñ‚"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("CH", {"switzerland", "ÑˆĞ²ĞµĞ¹Ñ†Ğ°Ñ€Ğ¸Ñ", "zurich", "Ñ†ÑÑ€Ğ¸Ñ…", "geneva", "Ğ¶ĞµĞ½ĞµĞ²Ğ°"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("PT", {"portugal", "Ğ¿Ğ¾Ñ€Ñ‚ÑƒĞ³Ğ°Ğ»Ğ¸Ñ", "lisbon", "Ğ»Ğ¸ÑÑĞ°Ğ±Ğ¾Ğ½", "porto", "Ğ¿Ğ¾Ñ€Ñ‚Ñƒ"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("HU", {"hungary", "Ğ²ĞµĞ½Ğ³Ñ€Ğ¸Ñ", "budapest", "Ğ±ÑƒĞ´Ğ°Ğ¿ĞµÑˆÑ‚"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("BE", {"belgium", "Ğ±ĞµĞ»ÑŒĞ³Ğ¸Ñ", "brussels", "Ğ±Ñ€ÑÑÑĞµĞ»ÑŒ"}, VisaCategory.STANDARD, "schengen"))
        self._add(Country("SCHENGEN", {"schengen", "ÑˆĞµĞ½Ğ³ĞµĞ½", "ÑˆĞµĞ½Ğ³ĞµĞ½ÑĞºÑƒÑ", "ÑˆĞµĞ½Ğ³ĞµĞ½ÑĞºĞ°Ñ", "europe", "ĞµĞ²Ñ€Ğ¾Ğ¿Ğ°", "ĞµĞ²Ñ€Ğ¾Ğ¿Ñƒ", "eu", "ĞµĞ²Ñ€Ğ¾ÑĞ¾ÑĞ·"}, VisaCategory.STANDARD, "schengen"))
        # ĞĞµÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ñ‹Ğµ
        self._add(Country("GB", {"uk", "united kingdom", "great britain", "england", "Ğ±Ñ€Ğ¸Ñ‚Ğ°Ğ½Ğ¸Ñ", "Ğ²ĞµĞ»Ğ¸ĞºĞ¾Ğ±Ñ€Ğ¸Ñ‚Ğ°Ğ½Ğ¸Ñ", "Ğ°Ğ½Ğ³Ğ»Ğ¸Ñ", "london", "Ğ»Ğ¾Ğ½Ğ´Ğ¾Ğ½"}, VisaCategory.NON_STANDARD, None, "âš ï¸ Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ Ğ±Ñ€Ğ¸Ñ‚Ğ°Ğ½ÑĞºĞ°Ñ Ğ²Ğ¸Ğ·Ğ°"))
        self._add(Country("CA", {"canada", "ĞºĞ°Ğ½Ğ°Ğ´Ğ°", "toronto", "Ñ‚Ğ¾Ñ€Ğ¾Ğ½Ñ‚Ğ¾", "vancouver", "Ğ²Ğ°Ğ½ĞºÑƒĞ²ĞµÑ€"}, VisaCategory.NON_STANDARD, None, "âš ï¸ Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ eTA Ğ¸Ğ»Ğ¸ Ğ²Ğ¸Ğ·Ğ°"))
        self._add(Country("AU", {"australia", "Ğ°Ğ²ÑÑ‚Ñ€Ğ°Ğ»Ğ¸Ñ", "sydney", "ÑĞ¸Ğ´Ğ½ĞµĞ¹", "melbourne", "Ğ¼ĞµĞ»ÑŒĞ±ÑƒÑ€Ğ½"}, VisaCategory.NON_STANDARD, None, "âš ï¸ Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ ETA Ğ¸Ğ»Ğ¸ Ğ²Ğ¸Ğ·Ğ°"))
        self._add(Country("JP", {"japan", "ÑĞ¿Ğ¾Ğ½Ğ¸Ñ", "tokyo", "Ñ‚Ğ¾ĞºĞ¸Ğ¾", "osaka", "Ğ¾ÑĞ°ĞºĞ°"}, VisaCategory.NON_STANDARD, None, "âš ï¸ Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ ÑĞ¿Ğ¾Ğ½ÑĞºĞ°Ñ Ğ²Ğ¸Ğ·Ğ°"))
        self._add(Country("CN", {"china", "ĞºĞ¸Ñ‚Ğ°Ğ¹", "beijing", "Ğ¿ĞµĞºĞ¸Ğ½", "shanghai", "ÑˆĞ°Ğ½Ñ…Ğ°Ğ¹"}, VisaCategory.NON_STANDARD, None, "âš ï¸ Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ ĞºĞ¸Ñ‚Ğ°Ğ¹ÑĞºĞ°Ñ Ğ²Ğ¸Ğ·Ğ°"))
        self._add(Country("KR", {"south korea", "korea", "ĞºĞ¾Ñ€ĞµÑ", "ÑĞ¶Ğ½Ğ°Ñ ĞºĞ¾Ñ€ĞµÑ", "seoul", "ÑĞµÑƒĞ»"}, VisaCategory.NON_STANDARD, None, "âš ï¸ Ğ¢Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ K-ETA Ğ¸Ğ»Ğ¸ Ğ²Ğ¸Ğ·Ğ°"))
        self._add(Country("TR", {"turkey", "Ñ‚ÑƒÑ€Ñ†Ğ¸Ñ", "istanbul", "ÑÑ‚Ğ°Ğ¼Ğ±ÑƒĞ»", "antalya", "Ğ°Ğ½Ñ‚Ğ°Ğ»Ğ¸Ñ"}, VisaCategory.NON_STANDARD, None, "âš ï¸ Ğ’Ğ¾Ğ·Ğ¼Ğ¾Ğ¶Ğ½Ğ° e-Visa"))
        self._add(Country("AE", {"uae", "emirates", "ÑĞ¼Ğ¸Ñ€Ğ°Ñ‚Ñ‹", "Ğ¾Ğ°Ñ", "dubai", "Ğ´ÑƒĞ±Ğ°Ğ¹"}, VisaCategory.NON_STANDARD))
        self._add(Country("TH", {"thailand", "Ñ‚Ğ°Ğ¸Ğ»Ğ°Ğ½Ğ´", "Ñ‚Ğ°Ğ¹Ğ»Ğ°Ğ½Ğ´", "bangkok", "Ğ±Ğ°Ğ½Ğ³ĞºĞ¾Ğº", "phuket", "Ğ¿Ñ…ÑƒĞºĞµÑ‚"}, VisaCategory.NON_STANDARD, None, "âš ï¸ Ğ‘ĞµĞ·Ğ²Ğ¸Ğ· Ğ´Ğ¾ 30 Ğ´Ğ½ĞµĞ¹"))
        self._add(Country("EG", {"egypt", "ĞµĞ³Ğ¸Ğ¿ĞµÑ‚", "cairo", "ĞºĞ°Ğ¸Ñ€", "sharm", "ÑˆĞ°Ñ€Ğ¼", "hurghada", "Ñ…ÑƒÑ€Ğ³Ğ°Ğ´Ğ°"}, VisaCategory.NON_STANDARD, None, "âš ï¸ Ğ’Ğ¸Ğ·Ğ° Ğ¿Ğ¾ Ğ¿Ñ€Ğ¸Ğ±Ñ‹Ñ‚Ğ¸Ğ¸"))
    
    def find_country(self, text: str) -> Optional[Country]:
        text_lower = text.lower()
        matches = [(code, len(kw)) for kw, code in self._keyword_index.items() if kw in text_lower]
        if not matches: return None
        matches.sort(key=lambda x: x[1], reverse=True)
        return self._countries.get(matches[0][0])
    
    def is_non_standard(self, code: str) -> bool:
        return code.upper() in self.NON_STANDARD_CODES

COUNTRY_DB = CountryDatabase()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”¬ ĞĞĞĞ›Ğ˜Ğ—ĞĞ¢ĞĞ Ğ«
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class TextAnalyzer:
    @staticmethod
    def normalize(text: str, max_len: int = 10000) -> str:
        text = re.sub(r'<[^>]+>', ' ', text)
        text = re.sub(r'\s+', ' ', text)
        return text[-max_len:].strip().lower() if len(text) > max_len else text.strip().lower()

class LanguageDetector(TextAnalyzer):
    MARKERS = {
        Language.ENGLISH: {"strong": ["dear ", "hello", "good afternoon", "please", "thank you", "regards"], "medium": ["the ", "and ", "for ", "with", "from", "have", "will"], "weak": ["is ", "are ", "was "]},
        Language.RUSSIAN: {"strong": ["ÑƒĞ²Ğ°Ğ¶Ğ°ĞµĞ¼Ñ‹Ğ¹", "Ğ·Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹Ñ‚Ğµ", "Ğ´Ğ¾Ğ±Ñ€Ñ‹Ğ¹ Ğ´ĞµĞ½ÑŒ", "Ñ ÑƒĞ²Ğ°Ğ¶ĞµĞ½Ğ¸ĞµĞ¼", "Ğ¿Ğ¾Ğ¶Ğ°Ğ»ÑƒĞ¹ÑÑ‚Ğ°", "ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾"], "medium": ["Ğ¿Ñ€Ğ¾ÑˆÑƒ", "Ğ½ĞµĞ¾Ğ±Ñ…Ğ¾Ğ´Ğ¸Ğ¼Ğ¾", "Ñ‚Ñ€ĞµĞ±ÑƒĞµÑ‚ÑÑ", "Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ", "Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ"], "weak": ["ÑÑ‚Ğ¾", "Ñ‡Ñ‚Ğ¾", "ĞºĞ°Ğº", "Ğ´Ğ»Ñ", "Ğ¸Ğ»Ğ¸"]},
        Language.KAZAKH: {"strong": ["ÑÓ™Ğ»ĞµĞ¼", "ÑÓ™Ğ»ĞµĞ¼ĞµÑ‚ÑÑ–Ğ·", "Ò›Ğ°Ğ¹Ñ‹Ñ€Ğ»Ñ‹", "Ñ€Ğ°Ñ…Ğ¼ĞµÑ‚"], "medium": ["ĞºĞµÑ€ĞµĞº", "Ğ±Ğ¾Ğ»Ğ°Ğ´Ñ‹"], "weak": ["Ğ±Ò±Ğ»", "Ğ¼ĞµĞ½"]},
    }
    WEIGHTS = {"strong": 3.0, "medium": 1.5, "weak": 0.5}
    
    def detect(self, messages: List[Message]) -> Language:
        text = self.normalize(" ".join(m.full_text for m in messages))
        scores = {lang: sum(text.count(w) * self.WEIGHTS[s] for s, ws in m.items() for w in ws) for lang, m in self.MARKERS.items()}
        best = max(scores, key=lambda k: scores[k])
        if best == Language.KAZAKH and scores[Language.RUSSIAN] > scores[Language.KAZAKH] * 0.5: return Language.RUSSIAN
        return Language.RUSSIAN if scores[best] < 1.0 else best

class IntentDetector(TextAnalyzer):
    PATTERNS = {
        Intent.WANT_APPLY: {"exact": ["Ñ…Ğ¾Ñ‡Ñƒ Ğ¿Ğ¾Ğ´Ğ°Ñ‚ÑŒ Ğ½Ğ° Ğ²Ğ¸Ğ·Ñƒ", "Ñ…Ğ¾Ñ‡Ñƒ Ğ¾Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ‚ÑŒ Ğ²Ğ¸Ğ·Ñƒ", "Ğ½ÑƒĞ¶Ğ½Ğ° Ğ²Ğ¸Ğ·Ğ°", "Ğ¾Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ‚ÑŒ Ğ²Ğ¸Ğ·Ñƒ", "i want to apply", "need a visa"], "combined": [(["Ğ²Ğ¸Ğ·", "Ğ½ÑƒĞ¶Ğ½"], 2.5), (["Ğ²Ğ¸Ğ·", "Ğ¾Ñ„Ğ¾Ñ€Ğ¼"], 2.5), (["visa", "apply"], 2.5)]},
        Intent.SEND_DOCS: {"exact": ["Ğ½Ğ°Ğ¿Ñ€Ğ°Ğ²Ğ»ÑÑ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹", "Ğ²Ñ‹ÑÑ‹Ğ»Ğ°Ñ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹", "Ğ²Ğ¾ Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½Ğ¸Ğ¸", "attached documents"], "combined": [(["Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚", "Ğ²Ğ»Ğ¾Ğ¶ĞµĞ½"], 2.5)]},
        Intent.INFO_REQUEST: {"exact": ["ĞºĞ°ĞºĞ¸Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹", "ÑĞºĞ¾Ğ»ÑŒĞºĞ¾ ÑÑ‚Ğ¾Ğ¸Ñ‚", "ĞºĞ°ĞºĞ¸Ğµ ÑÑ€Ğ¾ĞºĞ¸", "what documents", "how much"], "combined": [(["Ğ¿Ğ¾Ğ´ÑĞºĞ°Ğ¶Ğ¸Ñ‚Ğµ", "Ğ²Ğ¸Ğ·"], 1.5)]},
        Intent.FOLLOWUP: {"exact": ["ĞºĞ°ĞºĞ¾Ğ¹ ÑÑ‚Ğ°Ñ‚ÑƒÑ", "ĞµÑÑ‚ÑŒ Ğ½Ğ¾Ğ²Ğ¾ÑÑ‚Ğ¸", "any update", "status of"], "combined": [(["ÑÑ‚Ğ°Ñ‚ÑƒÑ", "Ğ²Ğ¸Ğ·"], 2.5)]},
        Intent.COMPLAINT: {"exact": ["Ğ½ĞµĞ´Ğ¾Ğ²Ğ¾Ğ»ĞµĞ½", "Ğ¶Ğ°Ğ»Ğ¾Ğ±Ğ°", "Ğ¿Ñ€ĞµÑ‚ĞµĞ½Ğ·Ğ¸Ñ", "complaint"], "combined": []},
        Intent.GRATITUDE: {"exact": ["ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾", "Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ", "thank you"], "combined": []},
        Intent.CANCELLATION: {"exact": ["Ğ¾Ñ‚Ğ¼ĞµĞ½Ğ¸Ñ‚ÑŒ", "Ğ¾Ñ‚ĞºĞ°Ğ·Ñ‹Ğ²Ğ°ÑÑÑŒ", "cancel"], "combined": [(["Ğ¾Ñ‚Ğ¼ĞµĞ½", "Ğ·Ğ°ÑĞ²Ğº"], 2.5)]},
        Intent.PAYMENT: {"exact": ["Ğ¾Ğ¿Ğ»Ğ°Ñ‚Ğ°", "ÑÑ‡Ñ‘Ñ‚", "Ğ¸Ğ½Ğ²Ğ¾Ğ¹Ñ", "payment", "invoice"], "combined": []},
    }
    
    def detect(self, messages: List[Message]) -> Tuple[Intent, float]:
        text = self.normalize(" ".join(m.full_text for m in messages))
        scores = {i: sum(3.5 for e in p.get("exact", []) if e in text) + sum(w for kws, w in p.get("combined", []) if all(k in text for k in kws)) for i, p in self.PATTERNS.items()}
        best = max(scores, key=lambda k: scores[k])
        conf = min(scores[best] / 7.0, 1.0)
        return (Intent.OTHER, 0.0) if conf < 0.25 else (best, conf)

class UrgencyDetector(TextAnalyzer):
    MARKERS = {
        UrgencyLevel.CRITICAL: ["Ğ²Ñ‹Ğ»ĞµÑ‚ ÑĞµĞ³Ğ¾Ğ´Ğ½Ñ", "Ğ²Ñ‹Ğ»ĞµÑ‚ Ğ·Ğ°Ğ²Ñ‚Ñ€Ğ°", "flight today", "flight tomorrow"],
        UrgencyLevel.HIGH: ["Ğ¾Ñ‡ĞµĞ½ÑŒ ÑÑ€Ğ¾Ñ‡Ğ½Ğ¾", "asap", "urgent", "ÑÑ€Ğ¾Ñ‡Ğ½Ğ¾"],
        UrgencyLevel.MEDIUM: ["ĞºĞ°Ğº Ğ¼Ğ¾Ğ¶Ğ½Ğ¾ ÑĞºĞ¾Ñ€ĞµĞµ", "Ğ½Ğ° ÑÑ‚Ğ¾Ğ¹ Ğ½ĞµĞ´ĞµĞ»Ğµ", "soon"],
    }
    def detect(self, messages: List[Message]) -> UrgencyLevel:
        text = self.normalize(" ".join(m.full_text for m in messages))
        for lvl in [UrgencyLevel.CRITICAL, UrgencyLevel.HIGH, UrgencyLevel.MEDIUM]:
            if any(m in text for m in self.MARKERS.get(lvl, [])): return lvl
        return UrgencyLevel.NORMAL

class SentimentDetector(TextAnalyzer):
    POS = {"ÑĞ¿Ğ°ÑĞ¸Ğ±Ğ¾", "Ğ±Ğ»Ğ°Ğ³Ğ¾Ğ´Ğ°Ñ€Ñ", "Ğ¾Ñ‚Ğ»Ğ¸Ñ‡Ğ½Ğ¾", "thank you", "great", "excellent"}
    NEG = {"Ğ½ĞµĞ´Ğ¾Ğ²Ğ¾Ğ»ĞµĞ½", "Ñ€Ğ°Ğ·Ğ¾Ñ‡Ğ°Ñ€Ğ¾Ğ²Ğ°Ğ½", "ÑƒĞ¶Ğ°ÑĞ½Ğ¾", "Ğ¶Ğ°Ğ»Ğ¾Ğ±Ğ°", "unhappy", "terrible"}
    def detect(self, messages: List[Message]) -> Sentiment:
        text = self.normalize(" ".join(m.full_text for m in messages))
        p, n = sum(1 for w in self.POS if w in text), sum(1 for w in self.NEG if w in text)
        if n > p: return Sentiment.NEGATIVE
        if p > n and p > 0: return Sentiment.POSITIVE
        return Sentiment.NEUTRAL


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ”„ ĞœĞĞ¨Ğ˜ĞĞ Ğ¡ĞĞ¡Ğ¢ĞĞ¯ĞĞ˜Ğ™ Ğ˜ Ğ›ĞĞ“Ğ˜ĞšĞ
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class StatusTransitionEngine:
    TRANSITIONS = {
        LeadStatus.NEW: {Intent.WANT_APPLY: LeadStatus.QUESTIONNAIRE_SENT, Intent.INFO_REQUEST: LeadStatus.INFO_PROVIDED, Intent.SEND_DOCS: LeadStatus.DOCS_IN_PROGRESS},
        LeadStatus.INFO_PROVIDED: {Intent.WANT_APPLY: LeadStatus.QUESTIONNAIRE_SENT, Intent.SEND_DOCS: LeadStatus.DOCS_IN_PROGRESS},
        LeadStatus.QUESTIONNAIRE_SENT: {Intent.SEND_DOCS: LeadStatus.QUESTIONNAIRE_FILLED},
        LeadStatus.QUESTIONNAIRE_FILLED: {Intent.SEND_DOCS: LeadStatus.DOCS_IN_PROGRESS},
        LeadStatus.CANCELLED: {Intent.WANT_APPLY: LeadStatus.QUESTIONNAIRE_SENT},
    }
    @classmethod
    def get_new_status(cls, current, intent): return cls.TRANSITIONS.get(current, {}).get(intent, current)

class QuestionnaireSelector:
    @staticmethod
    def should_offer(country, intent, existing):
        result = {"poland": False, "schengen": False, "usa": False, "generic": False}
        if country and country.category == VisaCategory.NON_STANDARD: return result
        if intent != Intent.WANT_APPLY: return result
        if country and country.questionnaire_type and not existing.get(country.questionnaire_type, False):
            result[country.questionnaire_type] = True
        elif not country and not existing.get("generic", False):
            result["generic"] = True
        return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ” Ğ“Ğ›ĞĞ’ĞĞ«Ğ™ ĞĞĞĞ›Ğ˜Ğ—ĞĞ¢ĞĞ 
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ThreadAnalyzer:
    def __init__(self):
        self.lang_det, self.intent_det, self.urg_det, self.sent_det = LanguageDetector(), IntentDetector(), UrgencyDetector(), SentimentDetector()
    
    def analyze(self, messages: List[Message], our_address: str = CONFIG.mailbox_upn, previous_status: str = None, existing_questionnaires: Dict[str, bool] = None) -> ThreadAnalysis:
        if not messages: return self._empty(previous_status)
        client_msgs = [m for m in messages if m.from_address.lower() != our_address.lower()] or messages
        
        lang = self.lang_det.detect(client_msgs)
        country = COUNTRY_DB.find_country(" ".join(m.full_text for m in client_msgs))
        intent, conf = self.intent_det.detect(client_msgs)
        urgency = self.urg_det.detect(client_msgs)
        sentiment = self.sent_det.detect(client_msgs)
        
        prev_status = LeadStatus.from_string(previous_status)
        new_status = StatusTransitionEngine.get_new_status(prev_status, intent)
        questionnaires = QuestionnaireSelector.should_offer(country, intent, existing_questionnaires or {})
        
        is_non_std = country and country.category == VisaCategory.NON_STANDARD
        total_att = sum(len(m.attachments) for m in messages)
        
        return ThreadAnalysis(
            language=lang, detected_country=country, intent=intent, urgency=urgency, sentiment=sentiment,
            previous_status=prev_status, new_status=new_status,
            offer_poland_questionnaire=questionnaires["poland"], offer_schengen_questionnaire=questionnaires["schengen"],
            offer_usa_questionnaire=questionnaires["usa"], offer_generic_questionnaire=questionnaires["generic"],
            is_non_standard_destination=is_non_std, has_attachments=total_att > 0, attachment_count=total_att,
            forward_to_email=CONFIG.non_standard_forward_email if is_non_std else None,
            forward_reason=f"non_standard:{country.code}" if is_non_std else None, confidence_score=conf,
        )
    
    def _empty(self, prev):
        p = LeadStatus.from_string(prev)
        return ThreadAnalysis(Language.RUSSIAN, None, Intent.OTHER, UrgencyLevel.NORMAL, Sentiment.NEUTRAL, p, p)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# âœ‰ï¸ Ğ“Ğ•ĞĞ•Ğ ĞĞ¢ĞĞ  ĞĞ¢Ğ’Ğ•Ğ¢ĞĞ’
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ReplyGenerator:
    def __init__(self, config=CONFIG, branding=AI_BRAND):
        self.config, self.branding = config, branding
    
    def generate(self, messages, analysis, q_links, extra_ctx=None, model=None, lead_id: Optional[Union[int, str]] = None):
        """
        Ğ“ĞµĞ½ĞµÑ€Ğ¸Ñ€ÑƒĞµÑ‚ Ğ¾Ñ‚Ğ²ĞµÑ‚. 
        lead_id Ğ¸ÑĞ¿Ğ¾Ğ»ÑŒĞ·ÑƒĞµÑ‚ÑÑ Ğ´Ğ»Ñ Ğ³ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ğ¸ ÑÑÑ‹Ğ»Ğ¾Ğº.
        """
        b = self.branding
        is_en = analysis.language == Language.ENGLISH
        
        # ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµĞ¼, ĞºĞ°ĞºÑƒÑ ÑÑÑ‹Ğ»ĞºÑƒ (Ğ¸Ğ»Ğ¸ ÑÑÑ‹Ğ»ĞºĞ¸) Ğ½ÑƒĞ¶Ğ½Ğ¾ Ğ¾Ñ‚Ğ¿Ñ€Ğ°Ğ²Ğ¸Ñ‚ÑŒ
        target_urls = self._resolve_target_urls(analysis, q_links, lead_id)
        
        sys_prompt = f"""You are {b.agent_name} v{b.agent_version} - intelligent AI assistant at {b.company_name}.

{b.robot_emoji} STYLE: Write clear, professional, empathetic emails. Be helpful and proactive.

{b.check_emoji} RULES:
1. Answer directly and completely.
2. NEVER invent facts about consulates, prices, or timelines.
3. If urgent, acknowledge and commit to priority.
4. IMPORTANT: I will provide you with specific questionnaire links. You MUST include them naturally in your response.

{b.info_emoji} TERMINOLOGY: Use "ĞĞŸĞ ĞĞ¡ĞĞ˜Ğš" (QUESTIONNAIRE), NOT "Ğ°Ğ½ĞºĞµÑ‚Ğ°" (form)!

{b.star_emoji} SIGNATURE (always include):
{b.line_thin}
{b.robot_emoji} {'This message was generated by' if is_en else 'Ğ¡Ğ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğµ ÑÑ„Ğ¾Ñ€Ğ¼Ğ¸Ñ€Ğ¾Ğ²Ğ°Ğ½Ğ¾'} {b.agent_name} v{b.agent_version}
{b.sparkle_emoji} {'Intelligent Visa Processing System' if is_en else 'Ğ˜Ğ½Ñ‚ĞµĞ»Ğ»ĞµĞºÑ‚ÑƒĞ°Ğ»ÑŒĞ½Ğ°Ñ ÑĞ¸ÑÑ‚ĞµĞ¼Ğ° Ğ¾Ğ±Ñ€Ğ°Ğ±Ğ¾Ñ‚ĞºĞ¸ Ğ²Ğ¸Ğ·Ğ¾Ğ²Ñ‹Ñ… Ğ·Ğ°ÑĞ²Ğ¾Ğº'}

{'Best regards' if is_en else 'Ğ¡ ÑƒĞ²Ğ°Ğ¶ĞµĞ½Ğ¸ĞµĞ¼'},
{b.company_name}
visa@bcdtravel.kz"""

        user_prompt = self._build_user_prompt(messages, analysis, target_urls, is_en)
        
        reply = generate_chat_completion([{"role": "system", "content": sys_prompt}, {"role": "user", "content": user_prompt}],
                                         model=model or self.config.default_model, max_tokens=self.config.max_tokens_reply, temperature=self.config.temperature)
        
        # ğŸ”¥ SAFETY NET: Ğ•ÑĞ»Ğ¸ AI Ğ·Ğ°Ğ±Ñ‹Ğ» ÑÑÑ‹Ğ»ĞºÑƒ, Ğ¼Ñ‹ ĞµÑ‘ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ¸Ğ¼
        return self._postprocess(reply, analysis, target_urls)
    
    def _resolve_target_urls(self, analysis, q_links, lead_id) -> Dict[str, str]:
        """
        ĞĞ¿Ñ€ĞµĞ´ĞµĞ»ÑĞµÑ‚, ĞºĞ°ĞºĞ¸Ğµ ÑÑÑ‹Ğ»ĞºĞ¸ Ğ´Ğ¾Ğ»Ğ¶Ğ½Ñ‹ Ğ±Ñ‹Ñ‚ÑŒ Ğ² Ğ¿Ğ¸ÑÑŒĞ¼Ğµ.
        Ğ’Ğ¾Ğ·Ğ²Ñ€Ğ°Ñ‰Ğ°ĞµÑ‚ ÑĞ»Ğ¾Ğ²Ğ°Ñ€ÑŒ {ĞĞ°Ğ·Ğ²Ğ°Ğ½Ğ¸Ğµ: URL}.
        """
        urls = {}
        if analysis.needs_questionnaire:
            if analysis.offer_poland_questionnaire and q_links.poland:
                urls["Poland"] = q_links.get_personal_link("poland", lead_id)
            if analysis.offer_schengen_questionnaire and q_links.schengen:
                urls["Schengen"] = q_links.get_personal_link("schengen", lead_id)
            if analysis.offer_usa_questionnaire and q_links.usa:
                urls["USA"] = q_links.get_personal_link("usa", lead_id)
            if analysis.offer_generic_questionnaire and q_links.generic:
                urls["Generic"] = q_links.get_personal_link("generic", lead_id)
        return urls
    
    def _build_user_prompt(self, messages, analysis, target_urls, is_en):
        b = self.branding
        parts = [f"{b.robot_emoji} ANALYSIS: Intent={analysis.intent.value}, Country={analysis.country_code or 'unknown'}, Urgency={analysis.urgency.emoji}{analysis.urgency.name}"]
        
        # --- Ğ˜Ğ—ĞœĞ•ĞĞ•ĞĞ˜Ğ• Ğ—Ğ”Ğ•Ğ¡Ğ¬ ---
        # ĞœÑ‹ Ğ¿ĞµÑ€ĞµĞ´Ğ°ĞµĞ¼ ÑÑÑ‹Ğ»ĞºĞ¸, Ğ½Ğ¾ Ğ¼ĞµĞ½ÑĞµĞ¼ Ğ¸Ğ½ÑÑ‚Ñ€ÑƒĞºÑ†Ğ¸Ñ
        if target_urls:
            url_list_str = "\n".join([f"- {k}: {v}" for k, v in target_urls.items()])
            parts.append(f"\n{b.form_emoji} POTENTIAL QUESTIONNAIRE LINKS (Use ONLY if relevant):\n{url_list_str}")
        
        conv = "\n---\n".join(f"From: {'BCD' if m.from_address.lower() == self.config.mailbox_upn.lower() else 'Client'}\n{m.get_clean_body()}" for m in messages)
        parts.append(f"\nğŸ“§ THREAD:\n{conv}")
        
        hints = []
        if analysis.is_urgent: hints.append(f"{b.urgent_emoji} URGENT - acknowledge urgency!")
        
        task = f"\n{b.robot_emoji} TASK: Write a professional reply."
        
        # --- Ğ“Ğ›ĞĞ’ĞĞĞ• Ğ£Ğ›Ğ£Ğ§Ğ¨Ğ•ĞĞ˜Ğ•: Ğ£ĞœĞĞ«Ğ™ Ğ¤Ğ˜Ğ›Ğ¬Ğ¢Ğ  ---
        if target_urls:
            task += """
CRITICAL INSTRUCTION ABOUT LINKS:
1. I have provided potential questionnaire links above.
2. ANALYZE the user's intent carefully.
3. IF the user is asking a theoretical question (e.g., "Do I need a visa?", "Is UK part of Schengen?"), DO NOT include the link. Answer the question only.
4. IF the user expresses a desire to apply (e.g., "I want to go", "How to start", "Send me the form"), THEN include the link naturally.
5. IF the user explicitly said "I don't need a questionnaire", DO NOT include it.
6. If you decide to include the link, embed it naturally in the text.
"""
            
        if hints: task += "\n" + "\n".join(hints)
        parts.append(task)
        
        return "\n\n".join(parts)
    
    def _postprocess(self, reply, analysis, target_urls):
        b = self.branding
        
        # 1. Ğ—Ğ°Ğ¼ĞµĞ½Ğ° Ñ‚ĞµÑ€Ğ¼Ğ¸Ğ½Ğ¾Ğ²
        if analysis.language != Language.ENGLISH:
            reply = re.sub(r'\bĞ°Ğ½ĞºĞµÑ‚[Ğ°Ñ‹ÑƒĞµĞ¾Ğ¹Ğ¸]?\b', 'Ğ¾Ğ¿Ñ€Ğ¾ÑĞ½Ğ¸Ğº', reply, flags=re.IGNORECASE)
        
        # 2. ğŸ”¥ SAFETY NET: ĞŸÑ€Ğ¾Ğ²ĞµÑ€ÑĞµĞ¼, Ğ²ÑÑ‚Ğ°Ğ²Ğ¸Ğ» Ğ»Ğ¸ AI ÑÑÑ‹Ğ»ĞºĞ¸
        # Ğ•ÑĞ»Ğ¸ ÑÑÑ‹Ğ»ĞºĞ° ĞµÑÑ‚ÑŒ Ğ² target_urls, Ğ½Ğ¾ ĞµÑ‘ Ğ½ĞµÑ‚ Ğ² Ñ‚ĞµĞºÑÑ‚Ğµ (reply), Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² Ğ±Ğ»Ğ¾Ğº P.S.
        missing_links = []
        for name, url in target_urls.items():
            if url and url not in reply:
                missing_links.append(f"{name}: {url}")
        
        if missing_links:
            # ĞĞºĞºÑƒÑ€Ğ°Ñ‚Ğ½Ğ¾ Ğ´Ğ¾Ğ±Ğ°Ğ²Ğ»ÑĞµĞ¼ Ğ² ĞºĞ¾Ğ½ĞµÑ†, Ğ¿ĞµÑ€ĞµĞ´ Ñ„ÑƒÑ‚ĞµÑ€Ğ¾Ğ¼ (ĞµÑĞ»Ğ¸ Ğ¿Ğ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑÑ) Ğ¸Ğ»Ğ¸ Ğ¿Ñ€Ğ¾ÑÑ‚Ğ¾ Ğ² ĞºĞ¾Ğ½ĞµÑ†
            safety_block = "\n\n" + (f"Link: " if len(missing_links) == 1 else "Links: ") + " ".join(missing_links)
            
            # ĞŸÑ‹Ñ‚Ğ°ĞµĞ¼ÑÑ Ğ²ÑÑ‚Ğ°Ğ²Ğ¸Ñ‚ÑŒ Ğ¿ĞµÑ€ĞµĞ´ Ğ»Ğ¸Ğ½Ğ¸ĞµĞ¹ Ñ„ÑƒÑ‚ĞµÑ€Ğ°
            if b.line_thin in reply:
                reply = reply.replace(b.line_thin, safety_block + "\n" + b.line_thin, 1)
            else:
                reply += safety_block

        # 3. Ğ¤ÑƒÑ‚ĞµÑ€
        if b.agent_name not in reply:
            reply += b.get_footer_en() if analysis.language == Language.ENGLISH else b.get_footer_ru()
        
        return reply.strip()


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸš€ ĞŸĞ£Ğ‘Ğ›Ğ˜Ğ§ĞĞ«Ğ• API
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _normalize_messages(data):
    if isinstance(data, str): return [Message("", "", data)]
    return [Message.from_dict(i) if isinstance(i, dict) else (i if isinstance(i, Message) else Message("", "", str(i))) for i in data]

def classify_message(thread_messages, our_address=CONFIG.mailbox_upn, previous_status=None,
                    existing_poland_questionnaire=False, existing_schengen_questionnaire=False,
                    existing_usa_questionnaire=False, existing_generic_questionnaire=False) -> Dict[str, Any]:
    """ğŸ” ĞšĞ»Ğ°ÑÑĞ¸Ñ„Ğ¸ĞºĞ°Ñ†Ğ¸Ñ ÑĞ¾Ğ¾Ğ±Ñ‰ĞµĞ½Ğ¸Ğ¹"""
    msgs = _normalize_messages(thread_messages)
    existing = {"poland": existing_poland_questionnaire, "schengen": existing_schengen_questionnaire, "usa": existing_usa_questionnaire, "generic": existing_generic_questionnaire}
    return ThreadAnalyzer().analyze(msgs, our_address, previous_status, existing).to_dict()

def generate_reply_from_thread(thread_messages_or_text, our_address=CONFIG.mailbox_upn, previous_status=None,
                               existing_poland_questionnaire=False, existing_schengen_questionnaire=False,
                               existing_usa_questionnaire=False, existing_generic_questionnaire=False,
                               questionnaire_links=None, extra_config=None, model=None) -> str:
    """âœ‰ï¸ Ğ“ĞµĞ½ĞµÑ€Ğ°Ñ†Ğ¸Ñ Ğ¾Ñ‚Ğ²ĞµÑ‚Ğ° Ñ AI-Ğ±Ñ€ĞµĞ½Ğ´Ğ¸Ğ½Ğ³Ğ¾Ğ¼"""
    msgs = _normalize_messages(thread_messages_or_text)
    existing = {"poland": existing_poland_questionnaire, "schengen": existing_schengen_questionnaire, "usa": existing_usa_questionnaire, "generic": existing_generic_questionnaire}
    analysis = ThreadAnalyzer().analyze(msgs, our_address, previous_status, existing)
    
    # Extract lead_id from extra_config if present
    lead_id = extra_config.get("lead_id") if extra_config else None
    
    return ReplyGenerator().generate(
        msgs, 
        analysis, 
        questionnaire_links or QuestionnaireLinks.from_config(), 
        extra_config, 
        model,
        lead_id=lead_id
    )

def analyze_single_message(text: str) -> Dict[str, Any]:
    """ğŸ§ª Ğ‘Ñ‹ÑÑ‚Ñ€Ñ‹Ğ¹ Ğ°Ğ½Ğ°Ğ»Ğ¸Ğ·"""
    return classify_message(text)

def get_ai_branding() -> AIBranding:
    """ğŸ¨ ĞŸĞ¾Ğ»ÑƒÑ‡Ğ¸Ñ‚ÑŒ Ğ±Ñ€ĞµĞ½Ğ´Ğ¸Ğ½Ğ³"""
    return AI_BRAND

def print_analysis_report(text: str):
    """ğŸ“Š ĞšÑ€Ğ°ÑĞ¸Ğ²Ñ‹Ğ¹ Ğ¾Ñ‚Ñ‡Ñ‘Ñ‚"""
    a = classify_message(text)
    print(f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘ {AI_BRAND.robot_emoji} {AI_BRAND.agent_name} v{AI_BRAND.agent_version} â€” ĞĞ¢Ğ§ĞĞ¢ ĞĞĞĞ›Ğ˜Ğ—Ğ                              â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸŒ Ğ¯Ğ·Ñ‹Ğº: {a['language']:<20} â•‘ ğŸ¯ ĞĞ°Ğ¼ĞµÑ€ĞµĞ½Ğ¸Ğµ: {a['intent']:<15} â•‘
â•‘ ğŸŒ Ğ¡Ñ‚Ñ€Ğ°Ğ½Ğ°: {(a['country'] or 'Ğ½Ğµ Ğ¾Ğ¿Ñ€ĞµĞ´ĞµĞ»ĞµĞ½Ğ°'):<18} â•‘ {a['urgency_emoji']} Ğ¡Ñ€Ğ¾Ñ‡Ğ½Ğ¾ÑÑ‚ÑŒ: {a['urgency_level']:<12} â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘ ğŸ“ˆ Ğ¡Ñ‚Ğ°Ñ‚ÑƒÑ: {a['previous_status']:<15} â†’ {a['new_status']:<15}                    â•‘
â•‘ ğŸ“‹ ĞĞ¿Ñ€Ğ¾ÑĞ½Ğ¸Ğº: {'Ğ”Ğ° (' + a['questionnaire_type'] + ')' if a['needs_questionnaire'] else 'ĞĞµÑ‚':<20}                                   â•‘
â•‘ âš ï¸ ĞĞµÑÑ‚Ğ°Ğ½Ğ´Ğ°Ñ€Ñ‚Ğ½Ğ¾Ğµ: {'Ğ”Ğ°' if a['is_non_standard_destination'] else 'ĞĞµÑ‚':<5}       ğŸ“Š Ğ£Ğ²ĞµÑ€ĞµĞ½Ğ½Ğ¾ÑÑ‚ÑŒ: {a['confidence_score']:.0%}                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
""")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ğŸ“¦ Ğ­ĞšĞ¡ĞŸĞĞ Ğ¢
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

__all__ = [
    "Message", "QuestionnaireLinks", "ThreadAnalysis", "Country", "Config", "AIBranding",
    "Language", "Intent", "LeadStatus", "UrgencyLevel", "VisaCategory", "Sentiment",
    "ThreadAnalyzer", "ReplyGenerator", "CountryDatabase",
    "classify_message", "generate_reply_from_thread", "analyze_single_message", "get_ai_branding", "print_analysis_report",
    "CONFIG", "COUNTRY_DB", "AI_BRAND",
]

if __name__ == "__main__":
    test = "Ğ—Ğ´Ñ€Ğ°Ğ²ÑÑ‚Ğ²ÑƒĞ¹Ñ‚Ğµ! Ğ¥Ğ¾Ñ‡Ñƒ Ğ¾Ñ„Ğ¾Ñ€Ğ¼Ğ¸Ñ‚ÑŒ Ğ²Ğ¸Ğ·Ñƒ Ğ² Ğ“ĞµÑ€Ğ¼Ğ°Ğ½Ğ¸Ñ Ğ´Ğ»Ñ Ğ´ĞµĞ»Ğ¾Ğ²Ğ¾Ğ¹ Ğ¿Ğ¾ĞµĞ·Ğ´ĞºĞ¸. Ğ¡Ñ€Ğ¾Ñ‡Ğ½Ğ¾, Ğ²Ñ‹Ğ»ĞµÑ‚ Ñ‡ĞµÑ€ĞµĞ· Ğ½ĞµĞ´ĞµĞ»Ñ. ĞšĞ°ĞºĞ¸Ğµ Ğ´Ğ¾ĞºÑƒĞ¼ĞµĞ½Ñ‚Ñ‹ Ğ½ÑƒĞ¶Ğ½Ñ‹?"
    print_analysis_report(test)